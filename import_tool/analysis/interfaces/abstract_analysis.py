from __future__ import division, print_function, unicode_literals


class AbstractAnalysis(object):
    """
    The AbstractAnalysis defines an interface into the TopicalGuide 
    import system's run_analysis method. This allows different analyses
    to be run without duplicating the import code.
    
    REMEMBER: Use the @property decorator if properties need to be 
    generated.
    
    The properties required to interface with the import system are:
    name -- the name to uniquely identify this analysis within the given
            dataset
    metadata -- dict with analysis metadata, description and
                readable_name are special entries that will be displayed
                to the user
    metadata_types -- return a dict mapping the metadata keys to their
                      datatypes (e.g. 'int', 'float', 'text', 'datetime').
    stopwords -- an iterable object containing strings
    excluded_words -- an iterable object containing strings, 
                      these differ from stopwords in that they 
                      are generated by an algorithm of some sort
    
    The required functions to interface with the import system are:
    run_analysis
    get_vocab_iterator
    get_token_iterator
    get_heirarchy_iterator
    
    The properties required to use the tg.py command line system are:
    find_bigrams -- boolean flag
    remove_singletons -- boolean flag
    stem_words -- boolean flag
    
    NOTES:
    Topic numbers must begin with zero and proceed from there.
    Tokens must be returned in the order that they occur in the corresponding document.
    """
    
    def __init__(self):
        """Initialize required fields."""
        self.name = ''
        self.metadata = {}
        self.metadata_types = {}
        self.stopwords = {}
        self.excluded_words = {}
        
        self.find_bigrams = False
        self.remove_singletons = False
        self.stem_words = False
    
    def run_analysis(self, document_iterator):
        """Perform the analysis.
        document_iterator -- an iterator over documents, the order 
                             iterated over indicates the document's index
        Each document has the methods get_content, the document text; and get_metadata, the associated metadata for the document.
        document_metadata_types -- the type of the metadata fields
        Return nothing.
        """
        raise NotImplementedError('run_analysis is not implemented')
    
    def get_vocab_iterator(self):
        """Return an iterator over the vocabulary."""
        raise NotImplementedError('get_vocab_iterator is not implemented')
    
    def get_token_iterator(self):
        """Return an iterator where each element is like: 
        (document_index, start_index, token, token_abstraction, topic_number_list).
        document_index -- the same index as given by the document_iterator
        start_index -- the location, as a character offset, of the word in the original text
        token -- unicode string of the token
        token_abstraction -- unicode string representing a type, e.g. the stem of the word
        topic_number_list -- a list of topic numbers
        Note that all 'token_index's must be returned in order.
        """
        raise NotImplementedError('get_token_iterator is not implemented')
    
    def get_hierarchy_iterator(self):
        """Return an iterator specifying the heirarchy.
        Each item is of the format (parent_topic, child_topic). 
        Return empty iterator if each topic has no parents."""
        raise NotImplementedError('get_heirarchy_iterator is not implemented')
