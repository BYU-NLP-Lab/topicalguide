COPYRIGHT INFO:

Turbo topics is licensed under the GPL from David Blei.  The original code can
be found here:
http://www.cs.princeton.edu/~blei/topicmodeling.html

We include only the files that we need.  In particular, the files
turbotopics.py, lda_topics.py, and turbotopics-readme.txt (renamed) are from
David Blei's code (we slightly modified lda_topics.py from Blei's version).
All other files in this directory are part of the Topical Guide, released under
the conditions specified at http://nlp.cs.byu.edu/topical_guide

--------------------------------------------------------------------------

USAGE INFO:

Just use backend.py to import turbo topics.  See the documentation at
http://nlps.cs.byu.edu/topical_guide for information on how to use backend.py
to run turbo topics.  That's the best way to get this to work.  If you don't
want to do that, follow the instructions below.

In order to add turbo topics information to the visualizer, you need two
things: a corpus file, and a mallet state file (unless you already know how to
run the turbo topics code, with LDA-C output, or something).

In order to run turbo topics from a mallet file with our pipeline, take the
mallet_input file (the file generated by the clustering codebase, which is
then converted into a serialized mallet object) without the prepended header
information, and use that as your corpus file.  Examine it and be sure it is
right; it should be one file, with one document per line.  Each line has the
filename, then the entire text of the document in a single line (after the
tokenization, but before the removal of stop words).

Then run create_files.py, giving it your mallet state file (decompressed) as
input.  That script will create two necessary files: assignments.txt and
words.txt.  You now have the three files that lda_topics.py expects as input:
the assignments file, the vocabulary file (words.txt), and the corpus file (as
described in the previous paragraph).  Run the code, giving it those files as
parameters.  There are also some other parameters to play around with; I won't
go into detail about them here.  An example command from the command line to
run turbo topics follows:

python lda_topics.py --assign=assignments.txt --corpus=corpus.txt --vocab=words.txt --out=gc_output/ --pval=0.001 --min-count=25 --perm --ntopics=150

The --out parameter is important, and it must be a directory (with a trailing
slash) for the add_to_database.py script to work correctly.  The --ntopics
parameter must match the number of topics used when running mallet to produce
the state file used previously.

When lda_topics.py finishes running (which may or may not take several days),
run the add_to_database.py script with the necessary parameters.  You will
need to run the script from the same place the django server is run, so that
it finds the database correctly.  Here is an example command to run the
add_to_database script:

python turbo_topics/add_to_database.py -d gc -a lda150topics -o turbo_topics/gc_output/

The options are similar to the topic metric scripts; -d is the database name
of the dataset and -a is the database name of the analysis. -o is the --out
directory specified when running turbo topics.
